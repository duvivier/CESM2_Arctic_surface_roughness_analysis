{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate seasonal vertical wind trends\n",
    "\n",
    "* **Description**: Reads in and creates cross section plots of wind trends\n",
    "* **Input data**: CESM2-LE and Rufmod output in timeseries format\n",
    "* **Output data**: PNG figures of trends\n",
    "* **Creator**: Alice DuVivier\n",
    "* **Date**: March 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rufmod experiments were performed where the sea ice roughness over Arctic sea ice regions was set to be equal to what it would be over open ocean. This is to better understand ice-atmosphere coupling, processes, and feedbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/duvivier/miniconda3/envs/analysis3/lib/python3.7/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "\n",
    "import pop_tools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import geocat.datafiles as gdf\n",
    "import geocat.viz.util as gvutil\n",
    "from geocat.viz import cmaps as gvcmaps\n",
    "import geocat.comp as gcomp\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy.stats import linregress,pearsonr, t\n",
    "\n",
    "import dask\n",
    "import intake\n",
    "from distributed import Client\n",
    "from ncar_jobqueue import NCARCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spin up dask cluster\n",
    "\n",
    "import dask\n",
    "\n",
    "# Use dask jobqueue\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "# Import a client\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Setup your PBSCluster\n",
    "cluster = PBSCluster(\n",
    "    cores=16, # The number of cores you want\n",
    "    memory='100 GB', # Amount of memory\n",
    "    processes=8, # How many processes\n",
    "    queue='casper', # The type of queue to utilize (/glade/u/apps/dav/opt/usr/bin/execcasper)\n",
    "    local_directory='$TMPDIR', # Use your local directory\n",
    "    #resource_spec='select=1:ncpus=2:mem=256GB', # Specify resources\n",
    "    project='P93300665', # Input your project ID here\n",
    "    walltime='04:00:00', # Amount of wall time\n",
    "    interface='ib0', # Interface to use\n",
    ")\n",
    "# Scale up\n",
    "cluster.scale(jobs=4)\n",
    "\n",
    "# Change your url to the dask dashboard so you can see it\n",
    "dask.config.set({'distributed.dashboard.link':'https://jupyterhub.hpc.ucar.edu/stable/user/{USER}/proxy/{port}/status'})\n",
    "\n",
    "# Setup your client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-1e45cd9c-a582-11ec-816b-3cecef1ac868</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/duvivier/proxy/8787/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/duvivier/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">ec6bc85b</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/duvivier/proxy/8787/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/duvivier/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-d3970099-2314-4eeb-8e75-f940d0c2ce1c</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.12.206.9:42837\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/duvivier/proxy/8787/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/duvivier/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.12.206.9:42837' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the variables to load\n",
    "var_in_1 = 'U'\n",
    "var_in_2 = 'V'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rufmod experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"rufmod\" data\n",
    "#choose cases and data paths\n",
    "case1 = 'b.e21.BSSP370.f09_g17.rufmod.001'\n",
    "case2 = 'b.e21.BSSP370.f09_g17.rufmod.002'\n",
    "case3 = 'b.e21.BSSP370.f09_g17.rufmod.003'\n",
    "case4 = 'b.e21.BSSP370.f09_g17.rufmod.004'\n",
    "case5 = 'b.e21.BSSP370.f09_g17.rufmod.005'\n",
    "\n",
    "# set base directory where all data live\n",
    "data_dir = '/glade/campaign/cesm/development/pcwg/duvivier/arctic_cyclones/'\n",
    "# set individual data directories\n",
    "data_dir1 = data_dir+case1+'/atm/proc/tseries/month_1/'\n",
    "data_dir2 = data_dir+case2+'/atm/proc/tseries/month_1/'\n",
    "data_dir3 = data_dir+case3+'/atm/proc/tseries/month_1/'\n",
    "data_dir4 = data_dir+case4+'/atm/proc/tseries/month_1/'\n",
    "data_dir5 = data_dir+case5+'/atm/proc/tseries/month_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading U\n",
      "loading V\n",
      "CPU times: user 1.71 s, sys: 466 ms, total: 2.17 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#reading in files\n",
    "print(\"loading \"+var_in_1)   \n",
    "ds1_1 = []\n",
    "ds2_1 = []\n",
    "ds3_1 = []\n",
    "ds4_1 = []\n",
    "ds5_1 = []\n",
    "my_files=sorted(glob.glob(data_dir1+case1+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds1_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir2+case2+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds2_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir3+case3+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds3_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')    \n",
    "my_files=sorted(glob.glob(data_dir4+case4+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds4_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir5+case5+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds5_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "\n",
    "print(\"loading \"+var_in_2)   \n",
    "ds1_2 = []\n",
    "ds2_2 = []\n",
    "ds3_2 = []\n",
    "ds4_2 = []\n",
    "ds5_2 = []\n",
    "my_files=sorted(glob.glob(data_dir1+case1+'.cam.h0.'+var_in_2+'.*.nc'))\n",
    "ds1_2=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir2+case2+'.cam.h0.'+var_in_2+'.*.nc'))\n",
    "ds2_2=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir3+case3+'.cam.h0.'+var_in_2+'.*.nc'))\n",
    "ds3_2=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')    \n",
    "my_files=sorted(glob.glob(data_dir4+case4+'.cam.h0.'+var_in_2+'.*.nc'))\n",
    "ds4_2=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir5+case5+'.cam.h0.'+var_in_2+'.*.nc'))\n",
    "ds5_2=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate them into a single array\n",
    "futures_1 = xr.concat([ds1_1,ds2_1,ds3_1,ds4_1,ds5_1],dim='member_id')\n",
    "futures_2 = xr.concat([ds1_2,ds2_2,ds3_2,ds4_2,ds5_2],dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set member_id values\n",
    "futures_1.member_id.values\n",
    "futures_2.member_id.values\n",
    "\n",
    "# assign member_id as coordinate array\n",
    "futures_1 = futures_1.assign_coords({\"member_id\": futures_1.member_id.values})\n",
    "futures_2 = futures_2.assign_coords({\"member_id\": futures_2.member_id.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift months by one to be center of time period.\n",
    "# Take average of the time bounds to get middle of month\n",
    "# will lose some attributes with time, so may need to put this back in later...\n",
    "futures_1['time'] = futures_1.time_bnds.load().mean(dim='nbnd').sel(member_id=0)\n",
    "futures_2['time'] = futures_2.time_bnds.load().mean(dim='nbnd').sel(member_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just NH slice\n",
    "futures_1_masked = futures_1.isel(lat=slice(164,192))\n",
    "futures_2_masked = futures_2.isel(lat=slice(164,192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab variables of interest\n",
    "U_rufmod = futures_1_masked[var_in_1]\n",
    "V_rufmod = futures_2_masked[var_in_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# actually load data\n",
    "U_rufmod.load()\n",
    "V_rufmod.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scalar wind speed\n",
    "WS_rufmod = np.sqrt(U_rufmod**2 + V_rufmod**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CESM-LE data \n",
    "\n",
    "We will use [`intake-esm`](https://intake-esm.readthedocs.io/en/latest/), which is a data catalog tool.\n",
    "It enables querying a database for the files we want, then loading those directly as an `xarray.Dataset`.\n",
    "\n",
    "First step is to set the \"collection\" for the CESM-LE, which depends on a json file conforming to the [ESM Catalog Specification](https://github.com/NCAR/esm-collection-spec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_file = '/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'\n",
    "\n",
    "cat = intake.open_esm_datastore(catalog_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing = 'cmip6'  # do not want smbb data\n",
    "expt = 'ssp370'\n",
    "comp = 'atm'\n",
    "freq = 'month_1'\n",
    "\n",
    "subset_1 = cat.search(variable=var_in_1, forcing_variant=forcing, experiment=expt, component=comp, frequency=freq )\n",
    "subset_2 = cat.search(variable=var_in_2, forcing_variant=forcing, experiment=expt, component=comp, frequency=freq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we only have cmip6, not smbb, data\n",
    "member_id = list(subset_1.df.experiment.unique())\n",
    "print(member_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    dsets_1 = subset_1.to_dataset_dict(cdf_kwargs={'chunks': {'time':50}, 'decode_times': True})\n",
    "#    dsets_1 = subset_1.to_dataset_dict(cdf_kwargs={'chunks': {'time':240}, 'decode_times': True})\n",
    "    \n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    dsets_2 = subset_2.to_dataset_dict(cdf_kwargs={'chunks': {'time':50}, 'decode_times': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the future datasets\n",
    "futures_1 = []\n",
    "for key in sorted(dsets_1.keys()):\n",
    "    futures_1.append(dsets_1[key])\n",
    "    print(key)\n",
    "\n",
    "futures_2 = []\n",
    "for key in sorted(dsets_2.keys()):\n",
    "    futures_2.append(dsets_2[key])\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ds_1 = xr.concat(futures_1, dim='member_id')\n",
    "future_ds_2 = xr.concat(futures_2, dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ds_1.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift months by one to be center of time period.\n",
    "# Take average of the time bounds to get middle of month\n",
    "# will lose some attributes with time, so may need to put this back in later...\n",
    "future_ds_1['time'] = future_ds_1.time_bnds.load().mean(dim='nbnd').sel(member_id='r1i1281p1f1')\n",
    "future_ds_2['time'] = future_ds_2.time_bnds.load().mean(dim='nbnd').sel(member_id='r1i1281p1f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just NH slice\n",
    "future_ds_1_masked = future_ds_1.isel(lat=slice(164,192))\n",
    "future_ds_2_masked = future_ds_2.isel(lat=slice(164,192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab variables of interest\n",
    "U_le = future_ds_1_masked[var_in_1]\n",
    "V_le = future_ds_2_masked[var_in_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_le.persist()\n",
    "V_le.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scalar wind speed\n",
    "WS_le = np.sqrt(U_le**2 + V_le**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# actually load data\n",
    "WS_le.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dask.config.get('jobqueue.pbs.log-directory'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate pressure on regular levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get surface pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need surface pressure and reference pressure for interpolation\n",
    "\n",
    "# set a surface reference pressure [Pa]\n",
    "p0 = 100000 \n",
    "\n",
    "# set variable name\n",
    "var_in_3 = 'PS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rufmod expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load surface pressure from rufmod\n",
    "print(\"loading rufmod \"+var_in_3)   \n",
    "ds1_3 = []\n",
    "ds2_3 = []\n",
    "ds3_3 = []\n",
    "ds4_3 = []\n",
    "ds5_3 = []\n",
    "my_files=sorted(glob.glob(data_dir1+case1+'.cam.h0.'+var_in_3+'.*.nc'))\n",
    "ds1_3=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir2+case2+'.cam.h0.'+var_in_3+'.*.nc'))\n",
    "ds2_3=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir3+case3+'.cam.h0.'+var_in_3+'.*.nc'))\n",
    "ds3_3=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')    \n",
    "my_files=sorted(glob.glob(data_dir4+case4+'.cam.h0.'+var_in_3+'.*.nc'))\n",
    "ds4_3=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir5+case5+'.cam.h0.'+var_in_3+'.*.nc'))\n",
    "ds5_3=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the datasets\n",
    "futures_3 = xr.concat([ds1_3,ds2_3,ds3_3,ds4_3,ds5_3],dim='member_id')\n",
    "\n",
    "# set member_id values\n",
    "futures_3.member_id.values\n",
    "\n",
    "# assign member_id as coordinate array\n",
    "futures_3.assign_coords({\"member_id\": futures_3.member_id.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift months by one to be center of time period.\n",
    "# Take average of the time bounds to get middle of month\n",
    "# will lose some attributes with time, so may need to put this back in later...\n",
    "futures_3['time'] = futures_3.time_bnds.load().mean(dim='nbnd').sel(member_id=0)\n",
    "\n",
    "# get just NH slice\n",
    "futures_3_masked = futures_3.isel(lat=slice(164,192))\n",
    "\n",
    "# grab variable of interest\n",
    "PS_rufmod = futures_3_masked[var_in_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CESM2-LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing = 'cmip6'  # do not want smbb data\n",
    "expt = 'ssp370'\n",
    "comp = 'atm'\n",
    "freq = 'month_1'\n",
    "\n",
    "subset_3 = cat.search(variable=var_in_3, forcing_variant=forcing, experiment=expt, component=comp, frequency=freq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    dsets_3 = subset_3.to_dataset_dict(cdf_kwargs={'chunks': {'time':240}, 'decode_times': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the future datasets\n",
    "futures_3 = []\n",
    "for key in sorted(dsets_3.keys()):\n",
    "    futures_3.append(dsets_3[key])\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ds_3 = xr.concat(futures_3, dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift months by one to be center of time period.\n",
    "# Take average of the time bounds to get middle of month\n",
    "# will lose some attributes with time, so may need to put this back in later...\n",
    "future_ds_3['time'] = future_ds_3.time_bnds.load().mean(dim='nbnd').sel(member_id='r1i1281p1f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just NH slice\n",
    "future_ds_3_masked = future_ds_3.isel(lat=slice(164,192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab variables of interest\n",
    "PS_le = future_ds_3_masked[var_in_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_le.load()\n",
    "PS_rufmod.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the vertical parameters necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab parameters for interpolation\n",
    "hyam_rufmod = futures_1_masked[\"hyam\"]\n",
    "hybm_rufmod = futures_1_masked[\"hybm\"]\n",
    "\n",
    "hyam_le = future_ds_1_masked[\"hyam\"]\n",
    "hybm_le = future_ds_1_masked[\"hybm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually load data\n",
    "hyam_rufmod.load()\n",
    "hybm_rufmod.load()\n",
    "\n",
    "hyam_le.load()\n",
    "hybm_le.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate to new pressure levels from hybrid levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify output pressure levels\n",
    "new_levels = np.array([1000, 975, 950, 925, 900, 875, 850, 825, 800, 775, 750, 700, 600, 500, 400, 300, 200])  # in millibars\n",
    "new_levels = new_levels * 100  # convert to Pascals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# interpolate le to the new levels\n",
    "# CESM2-LE\n",
    "WS_le_interp = gcomp.interp_hybrid_to_pressure(WS_le,\n",
    "                                               PS_le,\n",
    "                                               hyam_le, hybm_le, p0 = p0,\n",
    "                                               new_levels=new_levels,\n",
    "                                               method='linear')\n",
    "# SMOOTH\n",
    "WS_rufmod_interp = gcomp.interp_hybrid_to_pressure(WS_rufmod,\n",
    "                                                   PS_rufmod,\n",
    "                                                   hyam_rufmod, hybm_rufmod, p0 = p0,\n",
    "                                                   new_levels=new_levels,\n",
    "                                                   method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually load data\n",
    "WS_le_interp.load()\n",
    "WS_rufmod_interp.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_le_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mask Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Landfrac mask\n",
    "ds_masks = xr.open_mfdataset('/glade/p/cgd/ppc/duvivier/masks/b.e21.BSSP370.f09_g17.rufmod.001.cam.h0.2015-01.nc')\n",
    "my_mask = ds_masks['LANDFRAC'].isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mask = my_mask.isel(lat=slice(164,192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mask lat/lon to equal those from LE, otherwise masking below doesn't work properly\n",
    "my_mask['lat'] = PS_le['lat']\n",
    "my_mask['lon'] = PS_le['lon']\n",
    "\n",
    "# do same for the rufmod experiments\n",
    "WS_rufmod['lat'] = PS_le['lat']\n",
    "WS_rufmod['lon'] = PS_le['lon']\n",
    "PS_rufmod['lat'] = PS_le['lat']\n",
    "PS_rufmod['lon'] = PS_le['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep just ocean points\n",
    "PS_le = PS_le.where(my_mask<0.5)\n",
    "WS_le = WS_le.where(my_mask<0.5)\n",
    "\n",
    "PS_rufmod = PS_rufmod.where(my_mask<0.5)\n",
    "WS_rufmod = WS_rufmod.where(my_mask<0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate seasonal means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_names = ['OND','JFM', 'AMJ', 'JAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total years\n",
    "xarr_le = WS_zonal_le.coords['time.year'][(WS_zonal_le.coords['time.month']==1)]\n",
    "xarr_rufmod = WS_zonal_rufmod.coords['time.year'][(WS_zonal_rufmod.coords['time.month']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through seasons - rufmod\n",
    "\n",
    "# make numpy array to fill and specify dimensions we want\n",
    "seas_array_rufmod = np.zeros([len(season_names),len(xarr_rufmod),len(WS_zonal_rufmod.member_id),len(WS_zonal_rufmod.lev),len(WS_zonal_rufmod.lat)])\n",
    "\n",
    "for ss in season_names:\n",
    "    print(ss)\n",
    "    if ss == 'OND':\n",
    "        s_count = 0\n",
    "    else: \n",
    "        s_count = s_count+1\n",
    "    # get temporary array of just these month by season\n",
    "    if ss == 'JFM':\n",
    "        temp1 = WS_zonal_rufmod.isel(time=WS_zonal_rufmod.time.dt.month.isin([1,2,3]))\n",
    "    if ss == 'AMJ':\n",
    "        temp1 = WS_zonal_rufmod.isel(time=WS_zonal_rufmod.time.dt.month.isin([4,5,6]))\n",
    "    if ss == 'JAS':\n",
    "        temp1 = WS_zonal_rufmod.isel(time=WS_zonal_rufmod.time.dt.month.isin([7,8,9]))\n",
    "    if ss == 'OND':\n",
    "        temp1 = WS_zonal_rufmod.isel(time=WS_zonal_rufmod.time.dt.month.isin([10,11,12]))\n",
    "    # now loop through years to get the seasonal average by year for each ensemble member\n",
    "    for yy in xarr_rufmod:\n",
    "        if yy == 2015:\n",
    "            y_count = 0\n",
    "        else: \n",
    "            y_count = y_count+1 \n",
    "        # select only the indexes for this year\n",
    "        temp2 = temp1.isel(time=temp1.time.dt.year.isin([yy]))\n",
    "        temp3 = temp2.mean(dim='time')\n",
    "        seas_array_rufmod[s_count,y_count,:,:,:] = temp3    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through seasons - CESM2-LE\n",
    "\n",
    "# make numpy array to fill and specify dimensions we want\n",
    "seas_array_le = np.zeros([len(season_names),len(xarr_le),len(WS_zonal_le.member_id),len(WS_zonal_le.lev),len(WS_zonal_le.lat)])\n",
    "\n",
    "for ss in season_names:\n",
    "    print(ss)\n",
    "    if ss == 'OND':\n",
    "        s_count = 0\n",
    "    else: \n",
    "        s_count = s_count+1\n",
    "    # get temporary array of just these month by season\n",
    "    if ss == 'JFM':\n",
    "        temp1 = WS_zonal_le.isel(time=WS_zonal_le.time.dt.month.isin([1,2,3]))\n",
    "    if ss == 'AMJ':\n",
    "        temp1 = WS_zonal_le.isel(time=WS_zonal_le.time.dt.month.isin([4,5,6]))\n",
    "    if ss == 'JAS':\n",
    "        temp1 = WS_zonal_le.isel(time=WS_zonal_le.time.dt.month.isin([7,8,9]))\n",
    "    if ss == 'OND':\n",
    "        temp1 = WS_zonal_le.isel(time=WS_zonal_le.time.dt.month.isin([10,11,12]))\n",
    "    # now loop through years to get the seasonal average by year for each ensemble member\n",
    "    for yy in xarr_le:\n",
    "        if yy == 2015:\n",
    "            y_count = 0\n",
    "        else: \n",
    "            y_count = y_count+1 \n",
    "        # select only the indexes for this year\n",
    "        temp2 = temp1.isel(time=temp1.time.dt.year.isin([yy]))\n",
    "        temp3 = temp2.mean(dim='time')\n",
    "        seas_array_le[s_count,y_count,:,:,:] = temp3    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seas_array_le.shape)\n",
    "print(seas_array_rufmod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy array to a xarray for easier plotting\n",
    "WS_zonal_seas_le = xr.DataArray(seas_array_le,dims=('season','time','member_id','lev','lat'))\n",
    "WS_zonal_seas_rufmod = xr.DataArray(seas_array_rufmod,dims=('season','time','member_id','lev','lat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set coordinate arrays\n",
    "WS_zonal_seas_le['season'] = season_names\n",
    "WS_zonal_seas_le['time'] = xarr_le\n",
    "WS_zonal_seas_le['member_id'] = WS_zonal_le['member_id']\n",
    "WS_zonal_seas_le['lat'] = WS_zonal_le['lat'].values\n",
    "WS_zonal_seas_le['lev'] = WS_zonal_le['lev'].values\n",
    "\n",
    "WS_zonal_seas_rufmod['season'] = season_names\n",
    "WS_zonal_seas_rufmod['time'] = xarr_rufmod\n",
    "WS_zonal_seas_rufmod['member_id'] = WS_zonal_rufmod['member_id']\n",
    "WS_zonal_seas_rufmod['lat'] = WS_zonal_rufmod['lat'].values\n",
    "WS_zonal_seas_rufmod['lev'] = WS_zonal_rufmod['lev'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate ensemble mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ensemble means\n",
    "WS_zonal_seas_ens_mean_le = WS_zonal_seas_le.mean(dim='member_id')\n",
    "WS_zonal_seas_ens_mean_rufmod = WS_zonal_seas_rufmod.mean(dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_zonal_seas_ens_mean_le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Linear trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions from Liz Maroon\n",
    "# These allow us to do a linear regression at all points\n",
    "\n",
    "def pvalue_array(x,y,dname):\n",
    "    x_an=x-x.mean(dname)\n",
    "    slope=((x_an)*(y-y.mean(dname))).sum(dname)/((x_an)*(x_an)).sum(dname)\n",
    "    interc=y.mean(dname)-slope*x.mean(dname)\n",
    "    ypred=slope*x+interc  \n",
    "    n=len(x[dname])\n",
    "    mse=np.sqrt(((y-ypred)**2).sum(dname)/(n-2))\n",
    "    xsq=np.sqrt(((x_an)**2).sum(dname))\n",
    "    standerr=mse/xsq\n",
    "    pval=2*(1-t.cdf(np.abs(slope/standerr),n-2))\n",
    "    pval=xr.DataArray(pval,dims=standerr.dims,coords=standerr.coords)\n",
    "    return pval\n",
    "\n",
    "def rvalue_array(x,y,dname):  \n",
    "    xmean=x.mean(dname)\n",
    "    ymean=y.mean(dname)\n",
    "    numer=(x*y).mean(dname)-xmean*ymean\n",
    "    denom=np.sqrt(((x**2).mean(dname)-xmean**2)*\\\n",
    "                  (((y**2).mean(dname))-(ymean**2)))\n",
    "    return numer/denom\n",
    "\n",
    "def regcoeff_array(x,y,dname):\n",
    "    x_an=x-x.mean(dname)\n",
    "    y_an=y-y.mean(dname)\n",
    "    slope=(x_an*y_an).sum(dname)/(x_an*x_an).sum(dname)\n",
    "    return slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this with Liz's functions\n",
    "tseries = xarr_rufmod\n",
    "# grab first season only\n",
    "spatial = WS_zonal_seas_ens_mean_rufmod[0,:,:,:]\n",
    "# set time coordinate arrays to be equal\n",
    "tseries['time'] = spatial.time\n",
    "# calculate stats\n",
    "regcoeff=regcoeff_array(tseries,spatial,'time')\n",
    "rvalues=rvalue_array(tseries,spatial,'time')\n",
    "pvalues=pvalue_array(tseries,spatial,'time')\n",
    "# plot return\n",
    "regcoeff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_zonal_seas_ens_mean_rufmod.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the seasons to calculate regressions for full period\n",
    "ind_st = 5\n",
    "ind_ed = 85\n",
    "\n",
    "# make numpy array to fill and specify dimensions we want\n",
    "seas_array_rufmod = np.zeros([len(season_names),len(WS_zonal_rufmod.lev),len(WS_zonal_rufmod.lat)])\n",
    "seas_array_le = np.zeros([len(season_names),len(WS_zonal_le.lev),len(WS_zonal_le.lat)])\n",
    "\n",
    "for ss in season_names[0:1]:\n",
    "    print(ss)\n",
    "    if ss == 'OND':\n",
    "        s_count = 0\n",
    "    else: \n",
    "        s_count = s_count+1\n",
    "    # get data we want to regress\n",
    "    tseries = xarr_le[ind_st:ind_ed]\n",
    "    \n",
    "    # select only the indexes for this year\n",
    "    #    temp2 = temp1.isel(time=temp1.time.dt.year.isin([yy]))\n",
    "    #    temp3 = temp2.mean(dim='time')\n",
    "    #    seas_array_rufmod[s_count,y_count,:,:,:] = temp3    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_zonal_seas_ens_mean_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # grab data we want to regress\n",
    "    tseries = xarr_le[ind_st:ind_ed]\n",
    "    spatial_le = U10_seas_ens_mean_le[count,ind_st:ind_ed,:,:]\n",
    "    spatial_rufmod = U10_seas_ens_mean_rufmod[count,ind_st:ind_ed,:,:]\n",
    "    # set time coordinate arrays to be equal\n",
    "    spatial_rufmod['time'] = spatial_le.time\n",
    "    tseries['time'] = spatial_le.time\n",
    "\n",
    "    # Calculate CESM2-LE regressions (and convert to by decade)\n",
    "    regcoeff_le=10*regcoeff_array(tseries,spatial_le,'time')\n",
    "    rvalues_le=rvalue_array(tseries,spatial_le,'time')\n",
    "    pvalues_le=pvalue_array(tseries,spatial_le,'time')\n",
    "    regcoeff_le_masked = regcoeff_le.where(pvalues_le < sigval)\n",
    "\n",
    "    # Calculate rufmod regressions\n",
    "    regcoeff_rufmod=10*regcoeff_array(tseries,spatial_rufmod,'time')\n",
    "    rvalues_rufmod=rvalue_array(tseries,spatial_rufmod,'time')\n",
    "    pvalues_rufmod=pvalue_array(tseries,spatial_rufmod,'time')\n",
    "    regcoeff_rufmod_masked = regcoeff_rufmod.where(pvalues_rufmod < sigval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate zonal means\n",
    "WS_zonal_le = WS_le.mean(dim=\"lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_zonal_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the seasons to calculate regressions for full period\n",
    "ind_st = 5\n",
    "ind_ed = 85\n",
    "\n",
    "# set units\n",
    "units = '(m/s)'\n",
    "\n",
    "# set significance level (0.05 --> 95%; 0.01 --> 99%)\n",
    "sigval = 0.01\n",
    "\n",
    "#Plot each season and percent difference\n",
    "levels_in = np.arange(-0.2,0.25,0.05)\n",
    "cmap_in = plt.cm.get_cmap('coolwarm')\n",
    "levels_diff = np.arange(-70,80,10)\n",
    "#levels_diff = np.arange(-100,110,10)\n",
    "cmap_diff = plt.cm.get_cmap('bwr')\n",
    "\n",
    "#for ss in season_names[0:1]:\n",
    "for ss in season_names:\n",
    "    print('Calculating regressions for '+ss)\n",
    "    if ss == 'OND':\n",
    "        count = 0\n",
    "    else: \n",
    "        count = count+1\n",
    "    #print(count)\n",
    "\n",
    "    # grab data we want to regress\n",
    "    tseries = xarr_le[ind_st:ind_ed]\n",
    "    spatial_le = U10_seas_ens_mean_le[count,ind_st:ind_ed,:,:]\n",
    "    spatial_rufmod = U10_seas_ens_mean_rufmod[count,ind_st:ind_ed,:,:]\n",
    "    # set time coordinate arrays to be equal\n",
    "    spatial_rufmod['time'] = spatial_le.time\n",
    "    tseries['time'] = spatial_le.time\n",
    "\n",
    "    # Calculate CESM2-LE regressions (and convert to by decade)\n",
    "    regcoeff_le=10*regcoeff_array(tseries,spatial_le,'time')\n",
    "    rvalues_le=rvalue_array(tseries,spatial_le,'time')\n",
    "    pvalues_le=pvalue_array(tseries,spatial_le,'time')\n",
    "    regcoeff_le_masked = regcoeff_le.where(pvalues_le < sigval)\n",
    "\n",
    "    # Calculate rufmod regressions\n",
    "    regcoeff_rufmod=10*regcoeff_array(tseries,spatial_rufmod,'time')\n",
    "    rvalues_rufmod=rvalue_array(tseries,spatial_rufmod,'time')\n",
    "    pvalues_rufmod=pvalue_array(tseries,spatial_rufmod,'time')\n",
    "    regcoeff_rufmod_masked = regcoeff_rufmod.where(pvalues_rufmod < sigval)\n",
    "\n",
    "    # calculate difference - need to also set coordinates to be equal\n",
    "    regcoeff_rufmod_masked['lat'] = regcoeff_le_masked.lat.values\n",
    "    regcoeff_rufmod_masked['lon'] = regcoeff_le_masked.lon.values\n",
    "    diff = 100*((regcoeff_rufmod - regcoeff_le)/regcoeff_le)\n",
    "    diff = 100*((regcoeff_rufmod_masked - regcoeff_le_masked)/regcoeff_le_masked)\n",
    "        \n",
    "    # add cyclic point\n",
    "    regcoeff_le = gvutil.xr_add_cyclic_longitudes(regcoeff_le,\"lon\")\n",
    "    regcoeff_le_masked = gvutil.xr_add_cyclic_longitudes(regcoeff_le_masked,\"lon\")\n",
    "    regcoeff_rufmod = gvutil.xr_add_cyclic_longitudes(regcoeff_rufmod,\"lon\")    \n",
    "    regcoeff_rufmod_masked = gvutil.xr_add_cyclic_longitudes(regcoeff_rufmod_masked,\"lon\")\n",
    "    pvalues_le = gvutil.xr_add_cyclic_longitudes(pvalues_le,\"lon\")\n",
    "    pvalues_rufmod = gvutil.xr_add_cyclic_longitudes(pvalues_rufmod,\"lon\") \n",
    "    diff = gvutil.xr_add_cyclic_longitudes(diff,\"lon\")\n",
    "    \n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    fout = 'cesm2_le_and_rufmod_'+var_in_1+'_trends_2020_2100_'+ss\n",
    "    title = ss+' U10 trend over sea ice - 2020-2100'\n",
    "     \n",
    "    # Make subplots - note it's nrow x ncol x index (starting upper left)\n",
    "    # First subplot: CESM2-LE\n",
    "    ax = fig.add_subplot(1,3,1, projection=ccrs.NorthPolarStereo())\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "    ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "    this=ax.contourf(regcoeff_le.lon,regcoeff_le.lat,\n",
    "                       regcoeff_le,\n",
    "                       cmap=cmap_in,levels=levels_in,extend='both',\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    # add contour lines and labels\n",
    "    this2=ax.contour(regcoeff_le.lon,regcoeff_le.lat,\n",
    "                       regcoeff_le,\n",
    "                       colors='black',linestyles='solid',levels=levels_in,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    plt.gca().clabel(this2,this2.levels, inline=True, fontsize=10, colors='black')\n",
    "    # add significance overlay\n",
    "    sig = ax.pcolor(pvalues_le.lon,pvalues_le.lat,\n",
    "                       pvalues_le.where(pvalues_le > sigval),\n",
    "                       alpha=0, hatch='xx',\n",
    "                       transform=ccrs.PlateCarree())    \n",
    "    plt.gca().clabel(this2,this2.levels, inline=True, fontsize=10, colors='black')\n",
    "    cbar = plt.colorbar(this,orientation='horizontal',fraction=0.04,pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=15, labelrotation=45)\n",
    "    cbar.ax.set_xlabel(units+'/decade', fontsize=15)\n",
    "    plt.title('CESM2-LE',fontsize=20)\n",
    "\n",
    "    # Second subplot: Rufmod aka SMOOTH\n",
    "    ax = fig.add_subplot(1,3,2, projection=ccrs.NorthPolarStereo())\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "    ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "    this=ax.contourf(regcoeff_rufmod.lon,regcoeff_rufmod.lat,\n",
    "                       regcoeff_rufmod,\n",
    "                       cmap=cmap_in,levels=levels_in,extend='both',\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    # add contour lines and labels\n",
    "    this2=ax.contour(regcoeff_rufmod.lon,regcoeff_rufmod.lat,\n",
    "                       regcoeff_rufmod,\n",
    "                       colors='black',linestyles='solid',levels=levels_in,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    plt.gca().clabel(this2,this2.levels, inline=True, fontsize=10, colors='black')\n",
    "    # add significance overlay\n",
    "    sig = ax.pcolor(pvalues_rufmod.lon,pvalues_rufmod.lat,\n",
    "                       pvalues_rufmod.where(pvalues_rufmod > sigval),\n",
    "                       alpha=0, hatch='xx',\n",
    "                       transform=ccrs.PlateCarree())    \n",
    "    plt.gca().clabel(this2,this2.levels, inline=True, fontsize=10, colors='black')\n",
    "    cbar = plt.colorbar(this,orientation='horizontal',fraction=0.04,pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=15, labelrotation=45)\n",
    "    cbar.ax.set_xlabel(units+'/decade', fontsize=15)\n",
    "    plt.title('SMOOTH',fontsize=20)\n",
    "    \n",
    "    # Third subplot: %difference\n",
    "    ax = fig.add_subplot(1,3,3, projection=ccrs.NorthPolarStereo())\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "    ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "    this=ax.contourf(diff.lon,diff.lat,\n",
    "                       diff,\n",
    "                       cmap=cmap_diff,levels=levels_diff,extend='both',\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    # add contour lines and labels\n",
    "    this2=ax.contour(diff.lon,diff.lat,\n",
    "                       diff,\n",
    "                       colors='black',linestyles='solid',levels=levels_diff,\n",
    "                       transform=ccrs.PlateCarree())    \n",
    "    plt.gca().clabel(this2,this2.levels[::2], inline=True, fontsize=10, colors='black') \n",
    "    #print(this2.levels[::2]) # or [3:14] or [2::2]\n",
    "    \n",
    "    cbar = plt.colorbar(this,orientation='horizontal',fraction=0.04,pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=15, labelrotation=45)\n",
    "    cbar.ax.set_xlabel('% difference', fontsize=15)\n",
    "    plt.title('% Difference from CESM2-LE',fontsize=20)\n",
    "    \n",
    "    # Finalize figure and save\n",
    "    fig.suptitle(title,fontsize=15, y=0.75)  \n",
    "    fig.subplots_adjust(bottom=0.45,wspace=0.1)\n",
    "    #fig = plt.savefig(fout+'.png', bbox_inches='tight', dpi=200)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the seasons to calculate regressions for full period\n",
    "ind_st = 5\n",
    "ind_ed = 85\n",
    "\n",
    "# set units\n",
    "units = '(m/s)'\n",
    "\n",
    "# set significance level (0.05 --> 95%; 0.01 --> 99%)\n",
    "sigval = 0.01\n",
    "\n",
    "#Plot each season and percent difference\n",
    "levels_in = np.arange(-0.2,0.25,0.05)\n",
    "cmap_in = plt.cm.get_cmap('coolwarm')\n",
    "levels_diff = np.arange(-70,80,10)\n",
    "#levels_diff = np.arange(-100,110,10)\n",
    "cmap_diff = plt.cm.get_cmap('bwr')\n",
    "\n",
    "#for ss in season_names[0:1]:\n",
    "for ss in season_names:\n",
    "    print('Calculating regressions for '+ss)\n",
    "    if ss == 'OND':\n",
    "        count = 0\n",
    "    else: \n",
    "        count = count+1\n",
    "    #print(count)\n",
    "\n",
    "    # grab data we want to regress\n",
    "    tseries = xarr_le[ind_st:ind_ed]\n",
    "    spatial_le = U10_seas_ens_mean_le[count,ind_st:ind_ed,:,:]\n",
    "    spatial_rufmod = U10_seas_ens_mean_rufmod[count,ind_st:ind_ed,:,:]\n",
    "    # set time coordinate arrays to be equal\n",
    "    spatial_rufmod['time'] = spatial_le.time\n",
    "    tseries['time'] = spatial_le.time\n",
    "\n",
    "    # Calculate CESM2-LE regressions (and convert to by decade)\n",
    "    regcoeff_le=10*regcoeff_array(tseries,spatial_le,'time')\n",
    "    rvalues_le=rvalue_array(tseries,spatial_le,'time')\n",
    "    pvalues_le=pvalue_array(tseries,spatial_le,'time')\n",
    "    regcoeff_le_masked = regcoeff_le.where(pvalues_le < sigval)\n",
    "\n",
    "    # Calculate rufmod regressions\n",
    "    regcoeff_rufmod=10*regcoeff_array(tseries,spatial_rufmod,'time')\n",
    "    rvalues_rufmod=rvalue_array(tseries,spatial_rufmod,'time')\n",
    "    pvalues_rufmod=pvalue_array(tseries,spatial_rufmod,'time')\n",
    "    regcoeff_rufmod_masked = regcoeff_rufmod.where(pvalues_rufmod < sigval)\n",
    "\n",
    "    # calculate difference - need to also set coordinates to be equal\n",
    "    regcoeff_rufmod_masked['lat'] = regcoeff_le_masked.lat.values\n",
    "    regcoeff_rufmod_masked['lon'] = regcoeff_le_masked.lon.values\n",
    "    diff = 100*((regcoeff_rufmod - regcoeff_le)/regcoeff_le)\n",
    "    diff = 100*((regcoeff_rufmod_masked - regcoeff_le_masked)/regcoeff_le_masked)\n",
    "        \n",
    "    # add cyclic point\n",
    "    regcoeff_le = gvutil.xr_add_cyclic_longitudes(regcoeff_le,\"lon\")\n",
    "    regcoeff_le_masked = gvutil.xr_add_cyclic_longitudes(regcoeff_le_masked,\"lon\")\n",
    "    regcoeff_rufmod = gvutil.xr_add_cyclic_longitudes(regcoeff_rufmod,\"lon\")    \n",
    "    regcoeff_rufmod_masked = gvutil.xr_add_cyclic_longitudes(regcoeff_rufmod_masked,\"lon\")\n",
    "    pvalues_le = gvutil.xr_add_cyclic_longitudes(pvalues_le,\"lon\")\n",
    "    pvalues_rufmod = gvutil.xr_add_cyclic_longitudes(pvalues_rufmod,\"lon\") \n",
    "    diff = gvutil.xr_add_cyclic_longitudes(diff,\"lon\")\n",
    "    \n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    fout = 'cesm2_le_and_rufmod_'+var_in_1+'_trends_2020_2100_'+ss\n",
    "    title = ss+' U10 trend over sea ice - 2020-2100'\n",
    "     \n",
    "    # Make subplots - note it's nrow x ncol x index (starting upper left)\n",
    "    # First subplot: CESM2-LE\n",
    "    ax = fig.add_subplot(1,3,1, projection=ccrs.NorthPolarStereo())\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "    ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "    this=ax.contourf(regcoeff_le.lon,regcoeff_le.lat,\n",
    "                       regcoeff_le,\n",
    "                       cmap=cmap_in,levels=levels_in,extend='both',\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    # add significance overlay\n",
    "    sig = ax.pcolor(pvalues_le.lon,pvalues_le.lat,\n",
    "                       pvalues_le.where(pvalues_le > sigval),\n",
    "                       alpha=0, hatch='xx',\n",
    "                       transform=ccrs.PlateCarree())    \n",
    "    plt.gca().clabel(this2,this2.levels, inline=True, fontsize=10, colors='black')\n",
    "    cbar = plt.colorbar(this,orientation='horizontal',fraction=0.04,pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=15, labelrotation=45)\n",
    "    cbar.ax.set_xlabel(units+'/decade', fontsize=15)\n",
    "    plt.title('CESM2-LE',fontsize=20)\n",
    "\n",
    "    # Second subplot: Rufmod aka SMOOTH\n",
    "    ax = fig.add_subplot(1,3,2, projection=ccrs.NorthPolarStereo())\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "    ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "    this=ax.contourf(regcoeff_rufmod.lon,regcoeff_rufmod.lat,\n",
    "                       regcoeff_rufmod,\n",
    "                       cmap=cmap_in,levels=levels_in,extend='both',\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    # add significance overlay\n",
    "    sig = ax.pcolor(pvalues_rufmod.lon,pvalues_rufmod.lat,\n",
    "                       pvalues_rufmod.where(pvalues_rufmod > sigval),\n",
    "                       alpha=0, hatch='xx',\n",
    "                       transform=ccrs.PlateCarree())    \n",
    "    plt.gca().clabel(this2,this2.levels, inline=True, fontsize=10, colors='black')\n",
    "    cbar = plt.colorbar(this,orientation='horizontal',fraction=0.04,pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=15, labelrotation=45)\n",
    "    cbar.ax.set_xlabel(units+'/decade', fontsize=15)\n",
    "    plt.title('SMOOTH',fontsize=20)\n",
    "    \n",
    "    # Third subplot: %difference\n",
    "    ax = fig.add_subplot(1,3,3, projection=ccrs.NorthPolarStereo())\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "    ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "    this=ax.contourf(diff.lon,diff.lat,\n",
    "                       diff,\n",
    "                       cmap=cmap_diff,levels=levels_diff,extend='both',\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(this,orientation='horizontal',fraction=0.04,pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=15, labelrotation=45)\n",
    "    cbar.ax.set_xlabel('% difference', fontsize=15)\n",
    "    plt.title('% Difference from CESM2-LE',fontsize=20)\n",
    "    \n",
    "    # Finalize figure and save\n",
    "    fig.suptitle(title,fontsize=15, y=0.75)  \n",
    "    fig.subplots_adjust(bottom=0.45,wspace=0.1)\n",
    "    fig = plt.savefig(fout+'.png', bbox_inches='tight', dpi=200)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-analysis3]",
   "language": "python",
   "name": "conda-env-miniconda3-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
