{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot Mean Sea Level Pressure (PSL) contours\n",
    "\n",
    "* **Description**: Reads in and creates monthly average\n",
    "* **Input data**: Rufmod output in timeseries format\n",
    "* **Output data**: png with drag figure\n",
    "* **Creator**: Alice DuVivier\n",
    "* **Date**: August 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rufmod experiments were performed where the sea ice roughness over Arctic sea ice regions was set to be equal to what it would be over open ocean. This is to better understand ice-atmosphere coupling, processes, and feedbacks. The name of the experiments is \"rufmod\" but they include smoother ice and will be called \"smooth\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pop_tools\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import xesmf as xe\n",
    "import metpy as mp\n",
    "\n",
    "import dask\n",
    "import intake\n",
    "from distributed import Client\n",
    "from ncar_jobqueue import NCARCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spin up dask cluster\n",
    "\n",
    "import dask\n",
    "\n",
    "# Use dask jobqueue\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "# Import a client\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Setup your PBSCluster\n",
    "cluster = PBSCluster(\n",
    "    cores=2, # The number of cores you want\n",
    "    memory='32 GB', # Amount of memory\n",
    "    processes=1, # How many processes\n",
    "    queue='casper', # The type of queue to utilize (/glade/u/apps/dav/opt/usr/bin/execcasper)\n",
    "    local_directory='$TMPDIR', # Use your local directory\n",
    "    #resource_spec='select=1:ncpus=2:mem=256GB', # Specify resources\n",
    "    project='P93300665', # Input your project ID here\n",
    "    walltime='04:00:00', # Amount of wall time\n",
    "    interface='ib0', # Interface to use\n",
    ")\n",
    "# Scale up\n",
    "cluster.scale(32)\n",
    "\n",
    "# Change your url to the dask dashboard so you can see it\n",
    "dask.config.set({'distributed.dashboard.link':'https://jupyterhub.hpc.ucar.edu/stable/user/{USER}/proxy/{port}/status'})\n",
    "\n",
    "# Setup your client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the variables to load\n",
    "var_in_1 = 'PSL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load \"smooth\" experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"rufmod\" data\n",
    "#choose cases and data paths\n",
    "case1 = 'b.e21.BSSP370.f09_g17.rufmod.001'\n",
    "case2 = 'b.e21.BSSP370.f09_g17.rufmod.002'\n",
    "case3 = 'b.e21.BSSP370.f09_g17.rufmod.003'\n",
    "case4 = 'b.e21.BSSP370.f09_g17.rufmod.004'\n",
    "case5 = 'b.e21.BSSP370.f09_g17.rufmod.005'\n",
    "\n",
    "# set base directory where all data live\n",
    "data_dir = '/glade/campaign/cesm/development/pcwg/projects/arctic_cyclones/rufmod_expts/'\n",
    "# set individual data directories\n",
    "data_dir1 = data_dir+case1+'/atm/proc/tseries/month_1/'\n",
    "data_dir2 = data_dir+case2+'/atm/proc/tseries/month_1/'\n",
    "data_dir3 = data_dir+case3+'/atm/proc/tseries/month_1/'\n",
    "data_dir4 = data_dir+case4+'/atm/proc/tseries/month_1/'\n",
    "data_dir5 = data_dir+case5+'/atm/proc/tseries/month_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#reading in files\n",
    "print(\"loading \"+var_in_1)   \n",
    "ds1_1 = []\n",
    "ds2_1 = []\n",
    "ds3_1 = []\n",
    "ds4_1 = []\n",
    "ds5_1 = []\n",
    "my_files=sorted(glob.glob(data_dir1+case1+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds1_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir2+case2+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds2_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir3+case3+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds3_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')    \n",
    "my_files=sorted(glob.glob(data_dir4+case4+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds4_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')\n",
    "my_files=sorted(glob.glob(data_dir5+case5+'.cam.h0.'+var_in_1+'.*.nc'))\n",
    "ds5_1=xr.open_mfdataset(my_files,combine='by_coords',chunks={}, parallel=True, compat='override', coords='minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate them into a single array\n",
    "futures_1 = xr.concat([ds1_1,ds2_1,ds3_1,ds4_1,ds5_1],dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set member_id values\n",
    "futures_1.member_id.values\n",
    "# assign member_id as coordinate array\n",
    "futures_1.assign_coords({\"member_id\": futures_1.member_id.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift months by one to be center of time period.\n",
    "# Take average of the time bounds to get middle of month\n",
    "# will lose some attributes with time, so may need to put this back in later...\n",
    "futures_1['time'] = futures_1.time_bnds.load().mean(dim='nbnd').sel(member_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_1.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_smooth = futures_1[var_in_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_smooth.sel(member_id=0).isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CESM-LE data \n",
    "\n",
    "We will use [`intake-esm`](https://intake-esm.readthedocs.io/en/latest/), which is a data catalog tool.\n",
    "It enables querying a database for the files we want, then loading those directly as an `xarray.Dataset`.\n",
    "\n",
    "First step is to set the \"collection\" for the CESM-LE, which depends on a json file conforming to the [ESM Catalog Specification](https://github.com/NCAR/esm-collection-spec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_file = '/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'\n",
    "\n",
    "cat = intake.open_esm_datastore(catalog_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing = 'cmip6'  # do not want smbb data\n",
    "expt = 'ssp370'\n",
    "freq = 'month_1'\n",
    "\n",
    "subset_1 = cat.search(variable=var_in_1, forcing_variant=forcing, experiment=expt, frequency=freq )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we only have cmip6, not smbb, data\n",
    "member_id = list(subset_1.df.experiment.unique())\n",
    "print(member_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    dsets_1 = subset_1.to_dataset_dict(cdf_kwargs={'chunks': {'time':240}, 'decode_times': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the future datasets\n",
    "futures_1 = []\n",
    "for key in sorted(dsets_1.keys()):\n",
    "    futures_1.append(dsets_1[key])\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ds_1 = xr.concat(futures_1, dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ds_1.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift months by one to be center of time period.\n",
    "# Take average of the time bounds to get middle of month\n",
    "# will lose some attributes with time, so may need to put this back in later...\n",
    "future_ds_1['time'] = future_ds_1.time_bnds.load().mean(dim='nbnd').sel(member_id='r1i1281p1f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_le = future_ds_1[var_in_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_le.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_le.sel(member_id='r1i1281p1f1').isel(time=100).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert both to hPa from Pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_smooth = psl_smooth/100.\n",
    "psl_le = psl_le/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_le.sel(member_id='r1i1281p1f1').isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate seasonal means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_list = ['Autumn', 'Winter', 'Spring', 'Summer', 'Annual']\n",
    "season_names = ['OND','JFM', 'AMJ', 'JAS','ANN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total years\n",
    "xarr_le = psl_le.coords['time.year'][(psl_le.coords['time.month']==1)]\n",
    "xarr_smooth = psl_smooth.coords['time.year'][(psl_smooth.coords['time.month']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through seasons - rufmod\n",
    "\n",
    "# make numpy array to fill and specify dimensions we want\n",
    "seas_array_smooth = np.zeros([len(season_names),len(xarr_smooth),len(psl_smooth.member_id),len(psl_smooth.lat),len(psl_smooth.lon)])\n",
    "\n",
    "for ss in season_names:\n",
    "    print(ss)\n",
    "    if ss == 'OND':\n",
    "        s_count = 0\n",
    "    else: \n",
    "        s_count = s_count+1\n",
    "    # get temporary array of just these month by season\n",
    "    if ss == 'JFM':\n",
    "        temp1 = psl_smooth.isel(time=psl_smooth.time.dt.month.isin([1,2,3]))\n",
    "    if ss == 'AMJ':\n",
    "        temp1 = psl_smooth.isel(time=psl_smooth.time.dt.month.isin([4,5,6]))\n",
    "    if ss == 'JAS':\n",
    "        temp1 = psl_smooth.isel(time=psl_smooth.time.dt.month.isin([7,8,9]))\n",
    "    if ss == 'OND':\n",
    "        temp1 = psl_smooth.isel(time=psl_smooth.time.dt.month.isin([10,11,12]))\n",
    "    if ss == 'ANN':\n",
    "        temp1 = psl_smooth        \n",
    "    # now loop through years to get the seasonal average by year for each ensemble member\n",
    "    for yy in xarr_smooth:\n",
    "        if yy == 2015:\n",
    "            y_count = 0\n",
    "        else: \n",
    "            y_count = y_count+1 \n",
    "        # select only the indexes for this year\n",
    "        temp2 = temp1.isel(time=temp1.time.dt.year.isin([yy]))\n",
    "        temp3 = temp2.mean(dim='time')\n",
    "        seas_array_smooth[s_count,y_count,:,:,:] = temp3    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through seasons - CESM2-LE\n",
    "\n",
    "# make numpy array to fill and specify dimensions we want\n",
    "seas_array_le = np.zeros([len(season_names),len(xarr_le),len(psl_le.member_id),len(psl_le.lat),len(psl_le.lon)])\n",
    "\n",
    "for ss in season_names:\n",
    "    print(ss)\n",
    "    if ss == 'OND':\n",
    "        s_count = 0\n",
    "    else: \n",
    "        s_count = s_count+1\n",
    "    # get temporary array of just these month by season\n",
    "    if ss == 'JFM':\n",
    "        temp1 = psl_le.isel(time=psl_le.time.dt.month.isin([1,2,3]))\n",
    "    if ss == 'AMJ':\n",
    "        temp1 = psl_le.isel(time=psl_le.time.dt.month.isin([4,5,6]))\n",
    "    if ss == 'JAS':\n",
    "        temp1 = psl_le.isel(time=psl_le.time.dt.month.isin([7,8,9]))\n",
    "    if ss == 'OND':\n",
    "        temp1 = psl_le.isel(time=psl_le.time.dt.month.isin([10,11,12]))\n",
    "    if ss == 'ANN':\n",
    "        temp1 = psl_le        \n",
    "    # now loop through years to get the seasonal average by year for each ensemble member\n",
    "    for yy in xarr_le:\n",
    "        if yy == 2015:\n",
    "            y_count = 0\n",
    "        else: \n",
    "            y_count = y_count+1 \n",
    "        # select only the indexes for this year\n",
    "        temp2 = temp1.isel(time=temp1.time.dt.year.isin([yy]))\n",
    "        temp3 = temp2.mean(dim='time')\n",
    "        seas_array_le[s_count,y_count,:,:,:] = temp3    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seas_array_le.shape)\n",
    "print(seas_array_smooth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy array to a xarray for easier plotting\n",
    "psl_seas_le = xr.DataArray(seas_array_le,dims=('season','time','member_id','lat','lon'))\n",
    "psl_seas_smooth = xr.DataArray(seas_array_smooth,dims=('season','time','member_id','lat','lon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set coordinate arrays\n",
    "psl_seas_le['season'] = season_names\n",
    "psl_seas_le['time'] = xarr_le\n",
    "psl_seas_le['member_id'] = psl_le['member_id']\n",
    "psl_seas_le['lat'] = psl_le['lat'].values\n",
    "psl_seas_le['lon'] = psl_le['lon'].values\n",
    "\n",
    "psl_seas_smooth['season'] = season_names\n",
    "psl_seas_smooth['time'] = xarr_smooth\n",
    "psl_seas_smooth['member_id'] = psl_smooth['member_id']\n",
    "psl_seas_smooth['lat'] = psl_smooth['lat'].values\n",
    "psl_seas_smooth['lon'] = psl_smooth['lon'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_seas_smooth.isel(season=0,time=0,member_id=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_seas_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate decadal and ensemble means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify some arrays that will become coordinate arrays\n",
    "decades = list(range(2020,2100,10))\n",
    "decade_names = ['2020','2030','2040','2050','2060','2070','2080','2090']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through decades - rufmod\n",
    "print('Calculating Decadal and Ensemble Means - SMOOTH')\n",
    "\n",
    "# make numpy array to fill and specify dimensions we want\n",
    "array_smooth = np.zeros([len(decades),len(season_names),len(psl_seas_smooth.lat),len(psl_seas_smooth.lon)])\n",
    "\n",
    "# decade loop\n",
    "for dec in decades:\n",
    "    print('Calculating decadal means for '+str(dec)+'s')\n",
    "    # need to specify which spot in the array we'll fill for the decade\n",
    "    if dec == 2020:\n",
    "        count = 0\n",
    "    else: \n",
    "        count = count+1\n",
    "    # set the start and end years for this decade\n",
    "    yy_st = dec\n",
    "    yy_ed = yy_st + 10\n",
    "    yy = list(range(yy_st,yy_ed,1))\n",
    "    # subset the data for these years only but keep all months\n",
    "    temp1 = psl_seas_smooth.isel(time=psl_seas_smooth.time.isin([yy]))\n",
    "    # stack so we can average over years and ensembles at once\n",
    "    temp2 = temp1.stack(all_times=(\"time\",\"member_id\"))\n",
    "    # average over everything\n",
    "    array_smooth[count,:,:,:] = temp2.mean(dim='all_times')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through decades - CESM2-LE\n",
    "print('Calculating Decadal and Ensemble Means - CESM2-LE')\n",
    "\n",
    "# make numpy array to fill and specify dimensions we want\n",
    "array_le = np.zeros([len(decades),len(season_names),len(psl_seas_le.lat),len(psl_seas_le.lon)])\n",
    "\n",
    "# decade loop\n",
    "for dec in decades:\n",
    "    print('Calculating decadal means for '+str(dec)+'s')\n",
    "    # need to specify which spot in the array we'll fill for the decade\n",
    "    if dec == 2020:\n",
    "        count = 0\n",
    "    else: \n",
    "        count = count+1\n",
    "    # set the start and end years for this decade\n",
    "    yy_st = dec\n",
    "    yy_ed = yy_st + 10\n",
    "    yy = list(range(yy_st,yy_ed,1))\n",
    "    # subset the data for these years only but keep all months\n",
    "    temp1 = psl_seas_le.isel(time=psl_seas_le.time.isin([yy]))\n",
    "    # stack so we can average over years and ensembles at once\n",
    "    temp2 = temp1.stack(all_times=(\"time\",\"member_id\"))\n",
    "    # average over everything\n",
    "    array_le[count,:,:,:] = temp2.mean(dim='all_times')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array_smooth.shape)\n",
    "print(array_le.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy array to a xarray for easier plotting\n",
    "psl_seas_dec_le = xr.DataArray(array_le,dims=('decades','season','lat','lon'))\n",
    "psl_seas_dec_smooth = xr.DataArray(array_smooth,dims=('decades','season','lat','lon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set coordinate arrays\n",
    "psl_seas_dec_le['decades'] = decade_names\n",
    "psl_seas_dec_le['season'] = season_names\n",
    "psl_seas_dec_le['lat'] = psl_seas_le['lat'].values\n",
    "psl_seas_dec_le['lon'] = psl_seas_le['lon'].values\n",
    "\n",
    "psl_seas_dec_smooth['decades'] = decade_names\n",
    "psl_seas_dec_smooth['season'] = season_names\n",
    "psl_seas_dec_smooth['lat'] = psl_seas_smooth['lat'].values\n",
    "psl_seas_dec_smooth['lon'] = psl_seas_smooth['lon'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask everything below 70N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl_seas_dec_le = psl_seas_dec_le.where(psl_seas_dec_le.lat >70)\n",
    "psl_seas_dec_smooth = psl_seas_dec_smooth.where(psl_seas_dec_smooth.lat >70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make circular boundary for polar stereographic circular plots\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Plot - spatial plots by decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_names[4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set units\n",
    "units = 'hPa'\n",
    "\n",
    "#Plot each season and percent difference\n",
    "levels_in = np.arange(950,1050,2)  \n",
    "\n",
    "for ss in season_names[4:5]:\n",
    "    print('Plotting season '+ss)\n",
    "    \n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    fout = 'fig_4_decadal_'+var_in_1+'_'+ss\n",
    "    title = ss+' Mean Sea Level Pressure'\n",
    "    \n",
    "    for dd in decade_names:\n",
    "        if dd == '2020':\n",
    "            count = 1\n",
    "        else: \n",
    "            count = count+1\n",
    "        #print('Plotting drag for '+dd)\n",
    "        # grab data to plot\n",
    "        temp_le = psl_seas_dec_le.sel(decades=dd,season=ss)\n",
    "        temp_smooth = psl_seas_dec_smooth.sel(decades=dd,season=ss)\n",
    "        \n",
    "        # Make subplots - note it's nrow x ncol x index (starting upper left)\n",
    "        ax = fig.add_subplot(2,4,count, projection=ccrs.NorthPolarStereo())\n",
    "        ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "        ax.set_boundary(circle, transform=ax.transAxes)\n",
    "        ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "\n",
    "        #CESM2-LE\n",
    "        color = 'black'\n",
    "        this = ax.contour(temp_le.lon,temp_le.lat,\n",
    "                          temp_le,\n",
    "                          transform=ccrs.PlateCarree(),\n",
    "                          colors = color, levels = levels_in)\n",
    "        plt.clabel(this,colors=color,inline=1,fontsize=15,levels=levels_in)\n",
    "        #SMOOTH\n",
    "        color = 'blue'\n",
    "        this = ax.contour(temp_smooth.lon,temp_smooth.lat,\n",
    "                          temp_smooth,\n",
    "                          transform=ccrs.PlateCarree(),\n",
    "                          colors = color, levels = levels_in)\n",
    "        plt.clabel(this,colors=color,inline=1,fontsize=15,levels=levels_in)\n",
    "        # add title\n",
    "        plt.title(dd,fontsize=30)\n",
    "\n",
    "    # Finalize figure and save\n",
    "    #fig.suptitle(title,fontsize=15, y=0.95)  \n",
    "    #fig.subplots_adjust(bottom=0.45,wspace=0.1)\n",
    "    fig = plt.savefig(fout+'.png', bbox_inches='tight', dpi=200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set units\n",
    "units = 'hPa'\n",
    "\n",
    "#Plot each season and percent difference\n",
    "levels_in = np.arange(950,1050,2)  \n",
    "\n",
    "for ss in season_names[0:4]:\n",
    "    print('Plotting season '+ss)\n",
    "    if ss == 'OND':\n",
    "        s_count = 0\n",
    "    else:\n",
    "        s_count = s_count+1\n",
    "    \n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(40,10))\n",
    "    fout = 'decadal_'+var_in_1+'_'+ss\n",
    "    title = season_list[s_count]+' Mean Sea Level Pressure'\n",
    "    \n",
    "    for dd in decade_names:\n",
    "        if dd == '2020':\n",
    "            count = 1\n",
    "        else: \n",
    "            count = count+1\n",
    "        #print('Plotting drag for '+dd)\n",
    "        # grab data to plot\n",
    "        temp_le = psl_seas_dec_le.sel(decades=dd,season=ss)\n",
    "        temp_smooth = psl_seas_dec_smooth.sel(decades=dd,season=ss)\n",
    "        \n",
    "        # Make subplots - note it's nrow x ncol x index (starting upper left)\n",
    "        ax = fig.add_subplot(1,8,count, projection=ccrs.NorthPolarStereo())\n",
    "        ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "        ax.set_boundary(circle, transform=ax.transAxes)\n",
    "        ax.set_extent([0.005, 360, 90, 65], crs=ccrs.PlateCarree())\n",
    "\n",
    "        #CESM2-LE\n",
    "        color = 'black'\n",
    "        this = ax.contour(temp_le.lon,temp_le.lat,\n",
    "                          temp_le,\n",
    "                          transform=ccrs.PlateCarree(),\n",
    "                          colors = color, levels = levels_in)\n",
    "        plt.clabel(this,colors=color,inline=1,fontsize=10,levels=levels_in)\n",
    "        #SMOOTH\n",
    "        color = 'blue'\n",
    "        this = ax.contour(temp_smooth.lon,temp_smooth.lat,\n",
    "                          temp_smooth,\n",
    "                          transform=ccrs.PlateCarree(),\n",
    "                          colors = color, levels = levels_in)\n",
    "        plt.clabel(this,colors=color,inline=1,fontsize=10,levels=levels_in)\n",
    "        # add title\n",
    "        plt.title(dd,fontsize=20)\n",
    "\n",
    "    # Finalize figure and save\n",
    "    fig.suptitle(title,fontsize=15, y=0.75)  \n",
    "    #fig.subplots_adjust(bottom=0.45,wspace=0.1)\n",
    "    fig = plt.savefig(fout+'.png', bbox_inches='tight', dpi=200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-analysis2]",
   "language": "python",
   "name": "conda-env-miniconda3-analysis2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
